import torch, math
import torch.nn as nn
import torch.nn.functional as F
from einops import rearrange
from module.layers.src.encoding import *

# ----------------------------------
# 2. PE Factory - ìµœì‹  ê³ ì„±ëŠ¥ ë°©ë²•ë“¤ ì¶”ê°€!
# ----------------------------------
def build_pe(kind, d_model, max_len):
    if kind == "sin":
        return SinusoidalPE(d_model, max_len)
    elif kind == "learnable":
        return LearnableAbsPE(d_model, max_len)
    elif kind == "relative":
        return RelativePE(d_model, max_len)
    elif kind == "rope":
        return RotaryPE(d_model, max_len)
    elif kind == "time2vec":
        return Time2VecPE(d_model)
    elif kind == "time2vec2":
        return Time2VecPE2(d_model)
    elif kind == "tape":  # time Absolute Position Encoding
        return tAPE(d_model, max_len)
    elif kind == "tupe":  # Transformer with Untied Positional Encoding  
        return TUPE(d_model, max_len)
    elif kind == "conv_spe":  # Convolutional Sinusoidal PE
        return ConvSPE(d_model, max_len=max_len)
    elif kind == "temporal_pe":  # Temporal PE (T-PE)
        return TemporalPE(d_model, max_len)
    elif kind == "adaptive":  # ğŸš€ ìš°ë¦¬ì˜ í˜ì‹ ì  ë°©ë²•!
        return AdaptiveTemporalPE(d_model, max_len)
    elif kind == "fourier":  # Fourier-based PE
        return FourierPE(d_model, max_len)
    else:
        raise ValueError(f"Unknown PE: {kind}")

# ----------------------------------
# 3. Temporal Transformer Encoder
# ----------------------------------
class TemporalTransformerEncoder(nn.Module):
    """
    CLS í† í° + ì„ íƒí˜• Positional Encoding
    ğŸš€ ìƒˆë¡œìš´ ê³ ì„±ëŠ¥ PE ë°©ë²•ë“¤ ì§€ì›!
    
    kind âˆˆ {sin, learnable, relative, rope, time2vec, tape, tupe, conv_spe, temporal_pe, adaptive, fourier}
    """
    def __init__(self, config_predictor):
        super().__init__()
        self.max_len = config_predictor['pred_len']+1
        self.pe_kind = config_predictor['transformer']['pe_kind']      # ìœ ì € ì„¤ì •
        self.d_model = config_predictor['transformer']['d_model']
        self.num_heads = config_predictor['transformer']['num_heads']
        self.dim_feedforward = config_predictor['transformer']['dim_feedforward']
        self.dropout = config_predictor['transformer']['dropout']
        self.batch_first = config_predictor['transformer']['batch_first']
        self.num_layers = config_predictor['transformer']['num_layers']
        self.z_q_dim = config_predictor['vq_embed_dim']
        self.num_features = config_predictor['num_features']
        # ì‹œí€€ìŠ¤ ì „ì²´ ë°˜í™˜ ì—¬ë¶€
        self.return_sequence = config_predictor['transformer'].get('return_sequence', True)

        # Positional Encoding ëª¨ë“ˆ - ìƒˆë¡œìš´ ë°©ë²•ë“¤ í¬í•¨!
        self.pe = build_pe(self.pe_kind, self.d_model, self.max_len)

        # Transformer ë¸”ë¡ - í•­ìƒ ê¸°ë³¸ layer ì‚¬ìš©
        layer = nn.TransformerEncoderLayer(
            self.d_model,
            nhead=self.num_heads,
            dim_feedforward=self.dim_feedforward,
            dropout=self.dropout,
            batch_first=self.batch_first,
            # norm_first = True, # Trueí•˜ëŠ” ìˆœê°„ ì„±ëŠ¥ ë–¡ë½
            # activation = nn.GELU(),
        )
        self.z_q_proj = nn.Linear(self.z_q_dim, self.d_model)
        self.normalization = nn.LayerNorm(self.d_model)
        self.transformer = nn.TransformerEncoder(layer, num_layers=self.num_layers)
        
        # Input projection layer - ì…ë ¥ ì°¨ì›ì„ d_modelì— ë§ì¶¤
        self.input_proj = nn.Linear(self.num_features, self.d_model)

    def forward(self, x, z_q):                     # x: (B,T,D)
        B, T, D = x.shape
        
        # ì…ë ¥ ì°¨ì›ì´ d_modelê³¼ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ projectionìœ¼ë¡œ ë³€í™˜
        if D != self.d_model:
            x = self.input_proj(x)  # (B, T, D) -> (B, T, d_model)
            D = self.d_model  # ì°¨ì› ì—…ë°ì´íŠ¸

        # 1) z_që¥¼ ì „ì²´ ì‹œí€€ìŠ¤ì— ë”í•˜ê¸° (CLS ëŒ€ì‹  additive fusion)
        if z_q.shape[1] != D:
            z_q = self.z_q_proj(z_q)
        # z_që¥¼ CLS í† í°ì²˜ëŸ¼ ì‹œí€€ìŠ¤ ë§¨ ì•ì— ì¶”ê°€
        x = torch.cat((z_q.unsqueeze(1), x), dim=1)  # (B, 1+T, D)
        # x = self.normalization(x) # ! ì¼ë‹¨ normalizationì„ êº¼ë³´ì. 

        # 2) Positional Encoding
        if self.pe_kind in {"sin", "learnable", "time2vec", "tape", "conv_spe", "temporal_pe", "adaptive", "fourier"}:
            x = self.pe(x)
        elif self.pe_kind == "rope":
            # RoPE: ì¿¼ë¦¬Â·í‚¤ íšŒì „ì— ì§ì ‘ ì ìš©
            x_pe = self.pe.apply_rotary(x, T+1)  # (B,T+1,D)
            x = x_pe
        elif self.pe_kind == "tupe":
            # TUPE: ì‚¬ì „ ì ìš© ë°©ì‹ìœ¼ë¡œ ë³€ê²½ (í˜¸í™˜ì„± ë³´ì¥)
            x = self._apply_tupe_pe(x)
        # relative PEëŠ” attention ë‚´ë¶€ì„œ ì‚¬ìš© â†’ ìƒëµ

        # 3) Transform
        out = self.transformer(x)           # (B,T+1,D)
        
        # 4) CLS í† í°ë§Œ ë°˜í™˜ (ì‹œê³„ì—´ ëŒ€í‘œê°’)
        return out[:, 0]                   # (B,D)
    
    def _apply_tupe_pe(self, x):
        """TUPE PEë¥¼ ë¯¸ë¦¬ ì ìš©í•˜ëŠ” ì•ˆì „í•œ ë°©ë²•"""
        if hasattr(self.pe, 'pos_q') and hasattr(self.pe, 'pos_k'):
            seq_len = x.size(1)
            # ë‹¨ìˆœí™”: query position encodingë§Œ ì ìš©
            pos_encoding = self.pe.pos_q[:seq_len].unsqueeze(0)  # (1, T, d_model)
            return x + pos_encoding
        else:
            return x  # fallback
